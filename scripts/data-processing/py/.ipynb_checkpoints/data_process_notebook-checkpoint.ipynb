{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aec3919c-6b4a-4f6e-a90e-86826a594c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from pytablewriter import MarkdownTableWriter\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "\n",
    "%config Completer.use_jedi = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7f1e85-1826-436e-a58b-183b02924513",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "\n",
    "plt.rcParams.update({'axes.edgecolor': 'black', 'axes.linewidth': 2, \n",
    "                     'axes.grid': False, 'grid.linestyle': '--'})\n",
    "colors = ['#7a7ad8', '#6fcb9f', '#ffc663', '#ff7863', '#93d0fc']\n",
    "sns.palplot(colors)\n",
    "sns.set_palette(sns.color_palette(colors), 8, .75)\n",
    "sub_figure_title = {\"fontweight\": 700, 'fontname':'Arial', 'fontsize': 18}\n",
    "#plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ece721-4725-4f50-9842-daa52206fdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALGORITHM = [\"semantic-zest\", \"syntactic-zest\", \"semantic-noguidance\", \"syntactic-noguidance\"]\n",
    "ALGORITHM = [\"semantic-zest\", \"syntactic-zest\", \"semantic-noguidance\", \"syntactic-noguidance\",\"afl\"]\n",
    "\n",
    "RANGE=20 #exclusive range in python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1adf0c-cf8d-4fb8-b08f-eef8d304135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"/home/alena/source/growe/exps8\"\n",
    "\n",
    "folder = \"expfinal3\"\n",
    "base_path = f\"c:\\\\Users\\\\Alena\\\\source\\\\repos\\\\growe\\\\{folder}\\\\\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f3802e-101c-4241-a7f8-c07049a9ab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_cov_data(path: str) -> List[str]:\n",
    "    with open(path) as f:\n",
    "        return f.readlines()\n",
    "\n",
    "def add_rolling_mean( data : pd.DataFrame, rolling : int = 10) -> pd.DataFrame:\n",
    "    data['valid_inputs_percent']= data['valid_inputs'] / data['total_inputs']\n",
    "\n",
    "    # rolling mean to valid_covered_probes\n",
    "    data[f'rolling_{rolling}_valid_covered_probes'] = data['valid_covered_probes'].rolling(rolling).mean()\n",
    "    \n",
    "    # rolling mean to all_covered_probes\n",
    "    data[f'rolling_{rolling}_all_covered_probes'] = data['all_covered_probes'].rolling(rolling).mean()\n",
    "    \n",
    "    # rolling mean to total_inputs\n",
    "    data[f'rolling_{rolling}_total_inputs'] = data['total_inputs'].rolling(rolling).mean()\n",
    "\n",
    "    data['rolling_algorithm'] = data['algorithm'].astype(str) + f\"_rollingmean_{rolling}\"\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64165445-eeb8-42e1-8cfc-299fe21e3a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_plot_data(path: str, algorithm: str, idx: int) -> pd.DataFrame:\n",
    "    ps=os.path.join(path, 'plot_data')\n",
    "    #print(ps)\n",
    "    time_axis = \"# unix_time\"\n",
    "    if algorithm == \"afl\":\n",
    "        data = pd.read_csv(ps, sep=\",\", skipinitialspace=True,\n",
    "                       converters={\"valid_cov\": p2f, \"map_size\": p2f})\n",
    "    else:\n",
    "        data = pd.read_csv(ps, sep=\",\", skipinitialspace=True)\n",
    "\n",
    "    if data.empty: return None\n",
    "\n",
    "    data[time_axis] -= data[time_axis][0]\n",
    "    data['total_inputs'] = data['valid_inputs'] + data['invalid_inputs']\n",
    "    #data['total_inputs'] -= data[\"total_inputs\"][0]\n",
    "    data['valid_inputs_percent']= (data['valid_inputs'] / data['total_inputs'])\n",
    "\n",
    "    x_axis = time_axis\n",
    "    algo_data = data.copy().drop_duplicates(\n",
    "        keep='first', subset=[x_axis])\n",
    "    \n",
    "    algo_data['algorithm'] = [algorithm] * algo_data.shape[0]\n",
    "    algo_data[['generator','guidance']] = algo_data['algorithm'].str.split('-', expand=True)\n",
    "\n",
    "    algo_data['run'] = [idx] * algo_data.shape[0]\n",
    "  \n",
    "    return algo_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d83651-7799-4272-915b-9205235d9a6a",
   "metadata": {},
   "source": [
    "## READ ORIGINAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57357d2c-13b8-4283-94a8-641a5321a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ ORIGIANL DATA\n",
    "\n",
    "original_plot_data=[] # array of original dataframes\n",
    "\n",
    "for algorithm in ALGORITHM:\n",
    "    original_data_per_algo = []\n",
    "\n",
    "    for idx in range(0, RANGE):\n",
    "        path = os.path.join(base_path, f\"nextflow-{algorithm}-{idx}\", \"errorDir\")\n",
    "        if algorithm == \"afl\":\n",
    "            path = os.path.join(base_path, f\"nextflow-{algorithm}-{idx}\",\"fuzz-results\")\n",
    "        if not os.path.exists(path):\n",
    "            continue\n",
    "        #print(f\"processing: {path}\")\n",
    "\n",
    "        # plot_data from jqf afl run differs from other \n",
    "        if not algorithm == \"afl\" and os.path.exists(os.path.join(path,\"plot_data\")): \n",
    "            original_data = read_plot_data(path,algorithm,idx)\n",
    "            if original_data is None:\n",
    "                continue\n",
    "\n",
    "            original_data_per_algo.append(original_data)\n",
    "        \n",
    "    original_plot_data.extend([d for d in original_data_per_algo])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d2b693-0380-4467-9c32-6f9d308eaf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_exception_log(path: str, algorithm: str) -> pd.DataFrame:\n",
    "    ps=os.path.join(path, 'exception_log.csv')\n",
    "    #print(ps)\n",
    "    columns=[\"exception\",\"unique\",\"count\",\"file\",\"empty\"]\n",
    "    if algorithm != \"afl\":\n",
    "        data = pd.read_csv(ps, sep=\";\", header=None,names=columns)\n",
    "\n",
    "    if data.empty: return None\n",
    "    \n",
    "    data['algorithm'] = [algorithm] * data.shape[0]\n",
    "  \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07eee9d-b020-4897-a313-cc4efbcb147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ Exceptions\n",
    "\n",
    "exceptions_data = []\n",
    "exceptions_per_algo = []\n",
    "\n",
    "for algorithm in ALGORITHM:\n",
    "    \n",
    "    for idx in range(0, RANGE):\n",
    "   \n",
    "        path = os.path.join(base_path, f\"nextflow-{algorithm}-{idx}\", \"errorDir\")\n",
    "        if not os.path.exists(path):\n",
    "            continue\n",
    "        #print(f\"processing: {path}\")\n",
    "        if not algorithm == \"afl\" and os.path.exists(os.path.join(path,\"exception_log.csv\")): \n",
    "            exc = read_exception_log(path,algorithm)\n",
    "            if exc is None:\n",
    "                continue\n",
    "            exc['run']= [idx] * exc.shape[0]\n",
    "            exceptions_per_algo.append(exc)\n",
    "            \n",
    "exceptions_data = pd.concat(exceptions_per_algo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9d6ccd-536d-496d-8807-12d4fa782fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = exceptions_data[ exceptions_data['exception'].str.contains('Script')]\n",
    "\n",
    "pd.set_option('display.max_rows', 30)\n",
    "b=a[ a['algorithm'] == 'semantic-zest']  \n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fa9c2a-f36b-43b2-b8da-6efe05b6b9da",
   "metadata": {},
   "source": [
    "## interpolated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c66900-a2b5-401c-b81e-baba3d91f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolated data\n",
    "\n",
    "reindexsteps =5  \n",
    "interpolate = True\n",
    "\n",
    "time_based_plot_data = [] #dataframe with interpolated runs \n",
    "count_based_plot_data = [] #dataframe with interpolated runs\n",
    "\n",
    "first_idx=0\n",
    "time_range=3600\n",
    "for df in original_plot_data:\n",
    "    algorithm = df['algorithm'][0]\n",
    "    x_axis = \"# unix_time\"\n",
    "    time_based_data = df.copy().drop_duplicates(\n",
    "        keep='first', subset=[x_axis])\n",
    "    if interpolate:\n",
    "        time_based_data = time_based_data.set_index(x_axis).reindex(\n",
    "           range(1, time_range, reindexsteps)).interpolate().reset_index()\n",
    "        #resetting algo because it was overwritten by interpolation\n",
    "        time_based_data['algorithm'] = [algorithm] * time_based_data.shape[0]\n",
    "        time_based_data[['generator','guidance']] = time_based_data['algorithm'].str.split('-', expand=True)\n",
    "\n",
    "    time_based_data['valid_inputs_percent']= (time_based_data['valid_inputs'] / time_based_data['total_inputs'])\n",
    "\n",
    "    time_based_plot_data.append( time_based_data)\n",
    "    \n",
    "    x_axis = \"total_inputs\"\n",
    "    count_based_data = df.copy().drop_duplicates(\n",
    "        keep='first', subset=[x_axis])\n",
    "    if interpolate:\n",
    "        count_based_data = count_based_data.set_index(x_axis).reindex(\n",
    "           range(1, count_based_data[x_axis].max(), reindexsteps*8)).interpolate().reset_index()\n",
    "        #resetting algo because it was overwritten by interpolation\n",
    "        count_based_data['algorithm'] = [algorithm] * count_based_data.shape[0]\n",
    "        count_based_data[['generator','guidance']] = count_based_data['algorithm'].str.split('-', expand=True)\n",
    "        \n",
    "    count_based_data['valid_inputs_percent']= (count_based_data['valid_inputs'] / count_based_data['total_inputs'])\n",
    "    \n",
    "    count_based_plot_data.append(count_based_data)\n",
    "\n",
    "    \n",
    "    first_idx = first_idx +1\n",
    "#\n",
    "time_based_plot_data = pd.concat(time_based_plot_data, ignore_index=True, sort=False)\n",
    "count_based_plot_data = pd.concat(count_based_plot_data, ignore_index=True, sort=False)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f97327e-4871-4b28-9541-03fa4624628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_based_plot_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa61971f-4cb8-4e74-bc29-20a683ead762",
   "metadata": {},
   "source": [
    "## rolling mean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53961d28-8d38-4fe3-a18e-55c13e8c8052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling mean data\n",
    "\n",
    "ROLLING_MEAN=50\n",
    "\n",
    "rolling_time_based_plot_data = [] #dataframe with rolling mean over all runs\n",
    "rolling_count_based_plot_data = [] #dataframe with rolling mean over all runs\n",
    "\n",
    "complete_data_frame = pd.concat(original_plot_data, ignore_index=True, sort=False)\n",
    "for algorithm in ALGORITHM:\n",
    "    data_per_algo = complete_data_frame[complete_data_frame['algorithm'] == algorithm]\n",
    "\n",
    "    if data_per_algo is None or len(data_per_algo) == 0: continue\n",
    "\n",
    "    rolling_time_based_data_per_algo = data_per_algo.sort_values(by=['# unix_time'])\n",
    "    rolling_time_based_data_per_algo = add_rolling_mean(rolling_time_based_data_per_algo, ROLLING_MEAN)\n",
    "    rolling_time_based_plot_data.append(rolling_time_based_data_per_algo)\n",
    "\n",
    "    rolling_count_based_data_per_algo = data_per_algo.sort_values(by=['total_inputs'])\n",
    "    rolling_count_based_data_per_algo = add_rolling_mean(rolling_count_based_data_per_algo, ROLLING_MEAN)\n",
    "    rolling_count_based_plot_data.append(rolling_count_based_data_per_algo)\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "rolling_time_based_plot_data = pd.concat(rolling_time_based_plot_data, ignore_index=True, sort=True)\n",
    "rolling_count_based_plot_data = pd.concat(rolling_count_based_plot_data, ignore_index=True, sort=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1255b13f-a0f8-4dab-ac2b-2f3dea0d7cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafaca1a-bef4-4495-a171-7f9008c242f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_plot_data_base(data: pd.DataFrame, rolling_data:pd.DataFrame, x_axis: str, y_axis: str, path: str, errorbarname: str = 'se'):\n",
    "    print(x_axis, y_axis)\n",
    "    fig, ax1 = plt.subplots(figsize=(8,6))\n",
    "    #ax2 = ax1.twinx()\n",
    "\n",
    "    if errorbarname == 'se':\n",
    "        lineplot1 = sns.lineplot(x=x_axis, y=y_axis, hue='algorithm', errorbar=\"se\", hue_order=sorted(data['algorithm'].unique()), data=data, ax=ax1)\n",
    "   \n",
    "    elif errorbarname == 'sd':\n",
    "        lineplot1 = sns.lineplot(x=x_axis, y=y_axis, hue='algorithm', errorbar=(\"sd\",95), hue_order=sorted(data['algorithm'].unique()), data=data, ax=ax1)    \n",
    "    '''\n",
    "    y2=f\"rolling_{ROLLING_MEAN}_{y_axis}\"\n",
    "    if not y2 in rolling_data.columns:\n",
    "        y2 = y_axis\n",
    "    \n",
    "    lineplot2 = sns.lineplot(x=x_axis, \n",
    "                             y=y2, \n",
    "                             hue='rolling_algorithm', \n",
    "                             errorbar=None, \n",
    "                             hue_order=sorted(rolling_data['rolling_algorithm'].unique()), \n",
    "                             data=rolling_data, \n",
    "                             ax=ax1, \n",
    "                             palette=\"Set2\",\n",
    "                             linestyle=\"dotted\")\n",
    "    legend2 = lineplot2.legend()\n",
    "\n",
    "    leg_lines = legend2.get_lines()\n",
    "    for line in leg_lines[4:]:\n",
    "        line.set_linestyle(\":\")\n",
    "    \n",
    "    '''\n",
    "        \n",
    "    ax1.set_xlabel(x_axis)\n",
    "    ax1.set_ylabel(y_axis)\n",
    "    \n",
    "    lineplot1.set(title=path.split(\"/\")[-1][:-4].replace(\"_\",\" \"))\n",
    "   \n",
    "    # ax2.set_ylabel(f\"rolling_{ROLLING_MEAN}_{y_axis}\")\n",
    "\n",
    "    fig = ax1.get_figure()\n",
    "    fig.show()\n",
    "    fig.savefig(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6026112a-70fd-4e9c-a7fd-bf63d566cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "errorbrar = 'se'\n",
    "pdf_dir=f'pdfs_{folder}/'\n",
    "\n",
    "if not os.path.exists(os.path.join(\".\",pdf_dir)):\n",
    "    os.mkdir(os.path.join(\".\",pdf_dir))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb582e4-dee1-4bbf-a878-f17d3ba26a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_plot_data_base(time_based_plot_data, rolling_time_based_plot_data, \"# unix_time\", \"valid_covered_probes\", f\"{pdf_dir}valid_cov_over_time.pdf\", 'se')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34ed823-e430-45d5-a188-09d3792322a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,2,figsize=(16,5))\n",
    "x='# unix_time'\n",
    "lineplot1 = sns.lineplot(x=x, y='total_inputs', hue='algorithm', errorbar=\"se\", hue_order=sorted(time_based_plot_data['algorithm'].unique()), data=time_based_plot_data, ax=ax1[0])\n",
    "lineplot1.set_title(\"Inputs over time\")\n",
    "lineplot1.legend(loc='upper left')\n",
    "lineplot2 = sns.lineplot(x=x, \n",
    "                         y='execs_per_sec', \n",
    "                         hue='algorithm', \n",
    "                         errorbar=\"se\", \n",
    "                         hue_order=sorted(time_based_plot_data['algorithm'].unique()), \n",
    "                         data=time_based_plot_data, \n",
    "                         ax=ax1[1])\n",
    "lineplot2.set_title(\"Execution speed over time\")\n",
    "lineplot2.legend(loc='upper right')\n",
    "\n",
    "path=f\"{pdf_dir}/inputs_over_time.pdf\"\n",
    "\n",
    "\n",
    "fig.savefig(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0c8102-a39d-4381-a9bc-69fc469285fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,2,figsize=(16,5))\n",
    "x='# unix_time'\n",
    "lineplot1 = sns.lineplot(x=x, y='valid_covered_probes', \n",
    "                         hue='algorithm',\n",
    "                         errorbar=\"se\",\n",
    "                         hue_order=sorted(time_based_plot_data['algorithm'].unique()), \n",
    "                         data=time_based_plot_data, \n",
    "                         ax=ax1[0])\n",
    "lineplot1.set_title(\"valid covered branches over time\")\n",
    "lineplot1.legend(loc='lower right')\n",
    "x2='total_inputs'\n",
    "lineplot2 = sns.lineplot(x=x2, \n",
    "                         y='valid_covered_probes', \n",
    "                         hue='algorithm', \n",
    "                         hue_order=sorted(count_based_plot_data['algorithm'].unique()), \n",
    "                         errorbar=\"se\",\n",
    "                         data=count_based_plot_data, \n",
    "                         ax=ax1[1])\n",
    "lineplot2.set_title(\"valid covered branches over inputs\")\n",
    "lineplot2.legend(loc='lower right')\n",
    "\n",
    "path=f\"{pdf_dir}/covered_probes_time_and_inputs.pdf\"\n",
    "\n",
    "\n",
    "fig.savefig(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8537ed-fed3-4c96-864b-4a667e4e5a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d736ef1-d40d-476d-b27c-16f01ea298ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_plot_data_base(time_based_plot_data, rolling_time_based_plot_data, \"# unix_time\", \"valid_inputs\" , f\"{pdf_dir}valid_inputs_over_time.pdf\", errorbrar)\n",
    "\n",
    "#generate_plot_data_base(time_based_plot_data, rolling_time_based_plot_data, \"# unix_time\", \"invalid_inputs\" , f\"{pdf_dir}invalid_inputs_over_time.pdf\", errorbrar)\n",
    "#generate_plot_data_base(time_based_plot_data, rolling_time_based_plot_data, \"# unix_time\", \"all_covered_probes\", f\"{pdf_dir}all_cov_over_time.pdf\", errorbrar)\n",
    "\n",
    "#generate_plot_data_base(time_based_plot_data, rolling_time_based_plot_data, \"# unix_time\", \"total_inputs\" , f\"{pdf_dir}inputs_over_time.pdf\", errorbrar)\n",
    "#generate_plot_data_base(time_based_plot_data, rolling_time_based_plot_data, \"# unix_time\", \"valid_inputs\", f\"{pdf_dir}all_cov_over_time.pdf\", errorbrar)\n",
    "\n",
    "#generate_plot_data_base(time_based_plot_data, rolling_time_based_plot_data, \"# unix_time\", \"unique_crashes\", f\"{pdf_dir}crashes_over_time.pdf\", errorbrar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8d262f-2bca-404b-8824-dc084b64c3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(rolling_time_based_plot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dad88c0-9154-40d6-b0c8-efd979895e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4348c256-4db5-4fa2-8bcd-7ba65185d6a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdd993f-6c9c-446b-a6dc-e1f6523eef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "l ,axes  = plt.subplots(figsize=(8,6))\n",
    "plot= sns.lineplot(time_based_plot_data, \n",
    "                 y='valid_inputs_percent',\n",
    "                 x='# unix_time',\n",
    "                 hue='algorithm', \n",
    "                 errorbar='se',\n",
    "                 hue_order=sorted(time_based_plot_data['algorithm'].unique()),\n",
    "                 ax= axes)\n",
    "'''\n",
    "sns.lineplot(rolling_time_based_plot_data, \n",
    "                 y='valid_inputs_percent',\n",
    "                 x='# unix_time',\n",
    "                 hue='algorithm', \n",
    "                   errorbar='se',\n",
    "                 hue_order=ALGORITHM,\n",
    "                 ax= axes[1])\n",
    "                 \n",
    "'''\n",
    "plot.get_figure().savefig(f\"{pdf_dir}/valid_inputs_percent_over_time.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674e5141-f6f7-414b-aa34-b6401c8d9496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11b791f-07a0-41d6-bfee-a4b7325b5212",
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptions_data[10:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd17c078-9f91-4f43-ad01-e290d6d4976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for algo in ALGORITHM:\n",
    "    algo_data = exceptions_data[exceptions_data['algorithm'] == algo]\n",
    "    #print( algo)\n",
    "    #print(algo_data['exception'].value_counts())\n",
    "exceptions_count = exceptions_data.groupby(['exception','algorithm'])['algorithm'].count().to_frame()\n",
    "print(exceptions_count)\n",
    "\n",
    "exceptions_count.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a91f54-3942-4b6e-9a8d-b4cd859032c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique=exceptions_data[exceptions_data['unique'] == True]\n",
    "\n",
    "plot=sns.displot(exceptions_data, x='exception',hue='algorithm', height=4, aspect=1.5, multiple=\"dodge\")\n",
    "plot.tight_layout()\n",
    "\n",
    "for ax in plot.axes.flat:\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_rotation(40)\n",
    "        label.set_ha('right')\n",
    "    for p in ax.patches:\n",
    "        _x = p.get_x() + p.get_width() / 2\n",
    "        _y = p.get_y() + p.get_height() + 10\n",
    "        value = str(int(p.get_height()))\n",
    "        ax.text(_x, _y, value, ha=\"center\")    \n",
    "\n",
    "\n",
    "plot.savefig(f'{pdf_dir}/exceptions.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcffc99-0626-4426-928f-3d5e6b6050e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.savefig((os.path.join( pdf_dir, \"exceptions_logged.pdf\" )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b4bea-b750-41cf-9743-4742a4e40f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "for algo in ALGORITHM:\n",
    "    algodata = complete_data_frame[complete_data_frame['algorithm']==algo]\n",
    "    if not algodata.empty: \n",
    "        val1 = 0\n",
    "        val2 = 0\n",
    "        vt = 0\n",
    "        val3 = 0\n",
    "        val4 = 0\n",
    "        for i in range(RANGE):\n",
    "            d = algodata[algodata[\"run\"]==i]\n",
    "            m1 = d['valid_inputs'].max()\n",
    "            m2 =  d['invalid_inputs'].max()\n",
    "            mt = d['total_inputs'].max()\n",
    "            val1+=m1\n",
    "            val2+=m2\n",
    "            vt+=mt\n",
    "            m3=m1/mt\n",
    "            m4=m2/mt\n",
    "            v=d['valid_inputs_percent'].max()\n",
    "            #print(f\"algo {algo} run {i} valid:{m1} ({m3}%)  - invalid: {m2} ({m4}%) {v}\")\n",
    "        val3=(val1/vt)*100\n",
    "        val4=(val2/vt)*100\n",
    "        print(f\" {algo} & {vt} & {val1} ({val3:.2f}\\%) & {val2} ({val4:.2f}\\%) \\\\\\\\ \\\\ addlinespace\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c067fb-1077-40bf-9f11-d951c240ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique = unique[unique['algorithm'].isin(['semantic-noguidance','semantic-zest'])]\n",
    "l, axes = plt.subplots(2,2, figsize=(10,10),sharey=False)\n",
    "i=0\n",
    "cols = sns.color_palette(\"husl\",20)\n",
    "\n",
    "algo = 'semantic-zest'\n",
    "unique=rolling_time_based_plot_data[rolling_time_based_plot_data['algorithm'] == algo]\n",
    "if not unique.empty: \n",
    "    plot = sns.lineplot(data=unique, \n",
    "              x='# unix_time',\n",
    "              y='unique_crashes' ,\n",
    "              hue='run',\n",
    "              hue_order=sorted(unique['run'].unique()),\n",
    "              ax=axes[0,0],\n",
    "                  palette=cols)\n",
    "    plot.get_legend().set_visible(False)\n",
    "    plot.set_title(algo)\n",
    "\n",
    "algo = 'semantic-noguidance'\n",
    "unique=rolling_time_based_plot_data[rolling_time_based_plot_data['algorithm'] == algo]\n",
    "if not unique.empty: \n",
    "    plot = sns.lineplot(data=unique, \n",
    "              x='# unix_time',\n",
    "              y='unique_crashes' ,\n",
    "              hue='run',\n",
    "              hue_order=sorted(unique['run'].unique()),\n",
    "              ax=axes[0,1],\n",
    "                  palette=cols)\n",
    "    plot.get_legend().set_visible(False)\n",
    "    plot.set_title(algo)\n",
    "\n",
    "\n",
    "algo = 'syntactic-zest'\n",
    "unique=rolling_time_based_plot_data[rolling_time_based_plot_data['algorithm'] == algo]\n",
    "if not unique.empty: \n",
    "    plot = sns.lineplot(data=unique, \n",
    "              x='# unix_time',\n",
    "              y='unique_crashes' ,\n",
    "              hue='run',\n",
    "              hue_order=sorted(unique['run'].unique()),\n",
    "              ax=axes[1,0],\n",
    "                  palette=cols)\n",
    "    plot.get_legend().set_visible(False)\n",
    "    plot.set_title(algo)\n",
    "\n",
    "\n",
    "\n",
    "algo = 'syntactic-noguidance'\n",
    "unique=rolling_time_based_plot_data[rolling_time_based_plot_data['algorithm'] == algo]\n",
    "if not unique.empty: \n",
    "    plot = sns.lineplot(data=unique, \n",
    "              x='# unix_time',\n",
    "              y='unique_crashes' ,\n",
    "              hue='run',\n",
    "              hue_order=sorted(unique['run'].unique()),\n",
    "              ax=axes[1,1],\n",
    "                  palette=cols)\n",
    "    plot.get_legend().set_visible(False)\n",
    "    plot.set_title(algo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16375e5-a4e4-4c7f-a0e9-217cffdd11f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "l.savefig(os.path.join( pdf_dir, \"unique_crashes_per_run.pdf\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298b382a-b13e-4c43-af07-17c604041027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique = unique[unique['algorithm'].isin(['semantic-noguidance','semantic-zest'])]\n",
    "l, axes = plt.subplots(1,4, figsize=(25,5),sharey=True)\n",
    "i=0\n",
    "cols = sns.color_palette(\"husl\")\n",
    "\n",
    "for algo in ALGORITHM:\n",
    "\n",
    "    unique=rolling_time_based_plot_data[rolling_time_based_plot_data['algorithm'] == algo]\n",
    "    if not unique.empty: \n",
    "        plot = sns.lineplot(data=unique, \n",
    "                  x='# unix_time',\n",
    "                  y='valid_covered_probes' ,\n",
    "                  hue='run',\n",
    "                  hue_order=sorted(unique['run'].unique()),\n",
    "                  ax=axes[i],\n",
    "                  palette=cols)\n",
    "        plot.set_title(algo)\n",
    "        plot.get_legend().set_visible(False)\n",
    "    i+=1\n",
    "\n",
    "for ax in l.axes:\n",
    "    ax.tick_params(axis='y', labelleft=True)\n",
    "    \n",
    "l.savefig(os.path.join( pdf_dir, \"cov_per_run.pdf\" ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e244f2-e283-4060-aaff-eea27f3476ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique = unique[unique['algorithm'].isin(['semantic-noguidance','semantic-zest'])]\n",
    "l, axes = plt.subplots(1,4, figsize=(25,5),sharey=True)\n",
    "i=0\n",
    "cols = sns.color_palette(\"husl\")\n",
    "\n",
    "for algo in ALGORITHM:\n",
    "\n",
    "    unique=rolling_count_based_plot_data[rolling_count_based_plot_data['algorithm'] == algo]\n",
    "    if not unique.empty: \n",
    "        plot = sns.lineplot(data=unique, \n",
    "                  x='total_inputs',\n",
    "                  y='valid_covered_probes' ,\n",
    "                  hue='run',\n",
    "                  hue_order=sorted(unique['run'].unique()),\n",
    "                  ax=axes[i],\n",
    "                  palette=cols)\n",
    "        plot.set_title(algo)\n",
    "        plot.get_legend().set_visible(False)\n",
    "    i+=1\n",
    "\n",
    "for ax in l.axes:\n",
    "    ax.tick_params(axis='y', labelleft=True)\n",
    "    \n",
    "l.savefig(os.path.join( pdf_dir, \"cov_per_run_over_inputs.pdf\" ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fadbea7-d00c-4aee-a3bf-5cb5fb42f410",
   "metadata": {},
   "outputs": [],
   "source": [
    "for algo in ALGORITHM:\n",
    "    df = rolling_time_based_plot_data[rolling_time_based_plot_data['algorithm']==algo]\n",
    "    print(df.groupby(['run'])['valid_covered_probes'].max())\n",
    "    des1 =df['valid_covered_probes'].describe()\n",
    "    des2 = rolling_count_based_plot_data[rolling_time_based_plot_data['algorithm']==algo]['valid_inputs'].describe()\n",
    "    print(f\"-----{algo}----probes\")\n",
    "    print(des1)\n",
    "    print(f\"-----{algo}----inputs\")\n",
    "    print(des2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33366a0e-a4b7-4588-b08a-c84f063dcd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "# perform two-sided test. You can use 'greater' or 'less' for one-sided test\n",
    "df1 = rolling_time_based_plot_data[rolling_time_based_plot_data['generator'].str.match('semantic')].groupby(['run','generator'])['valid_inputs_percent'].last()#\n",
    "#df1 = time_based_plot_data[time_based_plot_data['algorithm'].str.match('semantic')]['valid_inputs_percent']\n",
    "df2 = rolling_time_based_plot_data[rolling_time_based_plot_data['generator'].str.match('syntactic')].groupby(['run','generator'])['valid_inputs_percent'].last()\n",
    "#df2 = time_based_plot_data[time_based_plot_data['algorithm'].str.match('syntactic')]['valid_inputs_percent']\n",
    "print(stats.mannwhitneyu(x=df1, y=df2, alternative = 'two-sided'))\n",
    "print(stats.mannwhitneyu(x=df1, y=df2, alternative = 'greater'))\n",
    "print(stats.mannwhitneyu(x=df1, y=df2, alternative = 'less'))\n",
    "print(stats.mannwhitneyu(x=df1, y=df2, method = 'exact'))\n",
    "print(stats.mannwhitneyu(x=df1, y=df2))\n",
    "\n",
    "print(df1.describe())\n",
    "print(df2.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1cea81-d918-41c8-921a-41d686e3bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_time_based_plot_data[rolling_time_based_plot_data['algorithm'].str.match('semantic')].groupby(['run','algorithm'])['valid_inputs_percent'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b58402a-111c-41e5-be6a-3194d7fe2add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform two-sided test. You can use 'greater' or 'less' for one-sided test\n",
    "\n",
    "d = complete_data_frame\n",
    "\n",
    "df1 = d[d['algorithm'].str.match('semantic-noguidance')].groupby(['run'])['valid_inputs_percent'].last()\n",
    "df2 = d[d['algorithm'].str.match('syntactic-noguidance')].groupby(['run'])['valid_inputs_percent'].last()\n",
    "print(stats.mannwhitneyu(x=df1, y=df2))\n",
    "print(df1.describe())\n",
    "print(df2.describe())\n",
    "\n",
    "df1 = d[d['algorithm'].str.match('semantic-noguidance')].groupby(['run'])['valid_covered_probes'].last()\n",
    "df2 = d[d['algorithm'].str.match('syntactic-noguidance')].groupby(['run'])['valid_covered_probes'].last()\n",
    "print(stats.mannwhitneyu(x=df1, y=df2))\n",
    "print(df1.describe())\n",
    "print(df2.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a13e8-0161-41d9-86c4-4dd4173513c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = complete_data_frame\n",
    "\n",
    "df1 = d[d['algorithm'].str.match('semantic-zest')].groupby(['run'])['valid_inputs_percent'].last()\n",
    "df2 = d[d['algorithm'].str.match('semantic-noguidance')].groupby(['run'])['valid_inputs_percent'].last()\n",
    "print(stats.mannwhitneyu(x=df1, y=df2))\n",
    "print(df1.describe())\n",
    "print(df2.describe())\n",
    "\n",
    "\n",
    "df1 = d[d['algorithm'].str.match('syntactic-zest')].groupby(['run'])['valid_inputs_percent'].last()\n",
    "df2 = d[d['algorithm'].str.match('syntactic-noguidance')].groupby(['run'])['valid_inputs_percent'].last()\n",
    "print(stats.mannwhitneyu(x=df1, y=df2))\n",
    "print(df1.describe())\n",
    "print(df2.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef04855c-0fdc-4445-9ea4-f9a4818c03ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = complete_data_frame\n",
    "df1 = d[d['algorithm'].str.match('semantic-zest')].groupby(['run'])['valid_covered_probes'].last()\n",
    "df2 = d[d['algorithm'].str.match('semantic-noguidance')].groupby(['run'])['valid_covered_probes'].last()\n",
    "print(stats.mannwhitneyu(x=df1, y=df2))\n",
    "print(df1.describe())\n",
    "print(df2.describe())\n",
    "\n",
    "df1 = d[d['algorithm'].str.match('syntactic-zest')].groupby(['run'])['valid_covered_probes'].last()\n",
    "df2 = d[d['algorithm'].str.match('syntactic-noguidance')].groupby(['run'])['valid_covered_probes'].last()\n",
    "print(stats.mannwhitneyu(x=df1, y=df2))\n",
    "print(df1.describe())\n",
    "print(df2.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f1c7c-e474-4ddf-b1b8-3bd40cba61e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=complete_data_frame\n",
    "a = d[d['algorithm'].str.match('semantic-noguidance')]\n",
    "b = d[d['algorithm'].str.match('syntactic-noguidance')]\n",
    "\n",
    "c = d[d['algorithm'].str.match('semantic-zest')]\n",
    "d = d[d['algorithm'].str.match('syntactic-zest')]\n",
    "\n",
    "print(a['valid_inputs_percent'].std()) \n",
    "print(a.groupby(['run'])['valid_inputs_percent'].last().describe()) \n",
    "\n",
    "\n",
    "print(b['valid_inputs_percent'].std())\n",
    "print(b.groupby(['run'])['valid_inputs_percent'].last().describe())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bfe64b-380e-406a-8e8b-05abda3cf86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d= complete_data_frame\n",
    "d[d['algorithm'].str.match('syntactic-noguidance')]['valid_inputs_percent'].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083939b3-10ea-4c39-b382-98e495a9506e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3426e05c-5836-4965-abb9-6b54fdb3335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = lambda x: np.std(x, ddof=1) / np.mean(x) * 100\n",
    "\n",
    "print(cv(c.groupby(['run'])['total_inputs'].last()) )\n",
    "print(cv(d.groupby(['run'])['total_inputs'].last()) )\n",
    "print(cv(a.groupby(['run'])['total_inputs'].last()) )\n",
    "print(cv(b.groupby(['run'])['total_inputs'].last()) )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
